{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as time \n",
    "import tkinter as tk \n",
    "import datetime\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8bc6f2",
   "metadata": {},
   "source": [
    "# Simple Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bdcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_downsmpl(img ,srf):\n",
    "  \n",
    "    im_array = np.array(img)\n",
    "    im_downsampled = im_array[::srf, ::srf, :]\n",
    "    return im_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90d73f",
   "metadata": {},
   "source": [
    "# Simple Upsampling --not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d34ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_upsmpl(img,srf):\n",
    "    \n",
    "    height, width ,col_ch = img.shape\n",
    "    upsampled_image = np.zeros((height * 2, width * 2,col_ch)).astype(int)\n",
    "    upsampled_image[::srf, ::srf,:] = img\n",
    "    return upsampled_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fa784",
   "metadata": {},
   "source": [
    "# Floating window for video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_file_location(event):\n",
    "    global file_path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry(\"250x150\")\n",
    "\n",
    "label = tk.Label(root, text=\"Select a file by \\n clicking on a floating window \\n \\n NOTE --> Close the window after selection\")\n",
    "label.pack(pady=35)\n",
    "\n",
    "\n",
    "label.bind(\"<Button-1>\", show_file_location)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a450ab",
   "metadata": {},
   "source": [
    "# Dark Channel Prior  -check pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCP(img,window):                                    \n",
    "    #Spliting image into inc=dividual color components--> \n",
    "    R=img[:,:,2]\n",
    "    G=img[:,:,1]\n",
    "    B=img[:,:,0]\n",
    "    h,w,c = img.shape\n",
    "    \n",
    "    #Flatening of image for loop jamming(reducing the number of loops) [other wise have to use 2 nested loop instead of 1]\n",
    "    R1 = np.ravel(R1)\n",
    "    G1 = np.ravel(G1)\n",
    "    B1 = np.ravel(B1)\n",
    "    min_col_ch_img = np.empty(R1.size)    #[check pt1] #may be R1.size = R.size (check)\n",
    "    \n",
    "    for i in range(0,R.size): \n",
    "        min_col_ch_img[i] = min(B1[i],G1[i],R1[i])\n",
    "    \n",
    "    #Reshaping back to 2D image--> \n",
    "    min_col_ch_img = min_col_ch_img.reshape(h,w)\n",
    " \n",
    "    kernel = np.ones((window,window), dtype = int)\n",
    "    dark_ch = cv2.erode(min_col_ch_img,kernel)\n",
    "    return dark_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8eb8a8",
   "metadata": {},
   "source": [
    "# Global atmospheric light estimator (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_estimator(img,dark_ch):\n",
    "    h,w,c = img.shape\n",
    "    \n",
    "    #Spliting image into individual color components--> \n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "    \n",
    "    #Flatening of image for loop jamming(reducing the number of loops) [other wise have to use 2 nested loop instead of 1]\n",
    "    B1 =B.ravel()\n",
    "    G1 =G.ravel()\n",
    "    R1 =R.ravel()\n",
    "    \n",
    "    #satcking flattened image to make 2d image in which [row 0] represents B coMponent ; [row 1] represents G component ;[row 2] represents R component \n",
    "    img1= np.vstack((B1,G1,R1))                \n",
    "    dark_ch = dark_ch.ravel()\n",
    "\n",
    "    #Descending order argsorting for 0.1% brightest pixel in dark_channel-->\n",
    "    top_point_1_perc = dark_ch.argsort()[::-1]\n",
    "    \n",
    "    Atm_sum = np.zeros([3])\n",
    "    for i in range(h*w//1000):\n",
    "        Atm_sum1[0]=AL_sum1[0] +img1[0][top_point_1_perc [i]]\n",
    "    for i in range(h*w//1000):\n",
    "        Atm_sum1[1]=AL_sum1[1] +img1[1][top_point_1_perc [i]]\n",
    "    for i in range(h*w//1000):\n",
    "        Atm_sum1[2]=AL_sum1[2] +img1[2][top_point_1_perc [i]] \n",
    "        \n",
    "    Atm_sum = Atm_sum.reshape([1,3])  \n",
    "    A = Atm_sum/(h*w//1000)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caccbd8a",
   "metadata": {},
   "source": [
    "# Estimating trans estimator using Aerial perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90493acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Trans_estimation(img, A, window, omega):\n",
    "    #omega = 0.95\n",
    "    img_temp = np.empty(img.shape, img.dtype)\n",
    "    for i in range(3):\n",
    "        img_temp[:,:,i] = img[:,:,i]/A[0,i]\n",
    "    trans = 1 - omega*DCP(img_temp, window)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc36d3",
   "metadata": {},
   "source": [
    "# Guided filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Guided_filter(img, tr,guide_area,eps):\n",
    "    img_mean = cv2.boxFilter(img, cv2.CV_64F, (guide_area ,guide_area))\n",
    "    tr_mean = cv2.boxFilter(tr, cv2.CV_64F, (guide_area ,guide_area))\n",
    "    img_corel = cv2.boxFilter(img*img, cv2.CV_64F, (guide_area ,guide_area))\n",
    "    img_t_corel = cv2.boxFilter(img*tr, cv2.CV_64F, (guide_area ,guide_area))\n",
    "    \n",
    "    img_var = img_corel - img_mean*img_mean\n",
    "    img_t_covar = img_t_corel - img_mean*tr_mean\n",
    "    \n",
    "    const_a = img_t_covar / (img_var + eps)\n",
    "    const_b = tr_mean - const_a*img_mean\n",
    "    \n",
    "    mean_a = cv2.boxFilter(const_a, cv2.CV_64F,(guide_area ,guide_area))\n",
    "    mean_b = cv2.boxFilter(const_b, cv2.CV_64F, (guide_area ,guide_area))\n",
    "    \n",
    "    result = mean_a * img + mean_b\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6eef5",
   "metadata": {},
   "source": [
    "# Main dehazing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dehaze(img, r, n ,window):    \n",
    "    #threshold\n",
    "    t_0 = 0.1\n",
    "    omega = 0.8\n",
    "    eps = 0.001\n",
    "    \n",
    "    normalized_img = np.float64(img)/255\n",
    "    dark_J = DCP(normalized_img, window)\n",
    "    A = A_estimator(normalized_img, dark_J)\n",
    "    t = Trans_estimation(normalized_img, A, r, omega)\n",
    "    \n",
    "    img_gs = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_gs = np.float64(img_gs)/255\n",
    "    guide_area =40\n",
    "    t_fil = Guided_filter(img_gs,t,guide_area,eps)\n",
    "    \n",
    "    t_thre = cv2.max(t_fil, t_0)\n",
    "    J = np.empty(normalized_img.shape, normalized_img.dtype)\n",
    "    for i in range(3):\n",
    "        J[:,:,i] = (normalized_img[:,:,i]-A[0,i])/t_thre + A[0,i]\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b6f1e",
   "metadata": {},
   "source": [
    "# Extracting frames from video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cfc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = file_path.replace(\"/\", \"\\\\\")\n",
    "\n",
    "vid_obj = cv2.VideoCapture(file_path)\n",
    "fps = vid_obj.get(cv2.CAP_PROP_FPS)\n",
    "no_of_frame = 0\n",
    "while(True):\n",
    "    success, frame = vid_obj.read()\n",
    "    if success==False:\n",
    "        break\n",
    "    no_of_frame += 1\n",
    "    print('Stored frame:', no_of_frame)\n",
    "    #params = []\n",
    "    #params.append(1)\n",
    "    cv2.imwrite(\"C:\\\\Users\\\\qa284\\\\Desktop\\\\major project final code settings\\\\@NEW BEGININIGS\\\\testing\\\\extracted_frames\\\\frame\" + \"_%d.png\" % no_of_frame, frame) #, params)\n",
    "vid_obj.release()\n",
    "# params is optional \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af593c",
   "metadata": {},
   "source": [
    "# Critical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=5\n",
    "n=8\n",
    "window = 11\n",
    "srf =2 #srf is sampling rate factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10410eb",
   "metadata": {},
   "source": [
    "# Dehazing frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fc=[]\n",
    "y_time=[]\n",
    "\n",
    "\n",
    "\n",
    "for f in range(1,no_of_frame+1):\n",
    "    \n",
    "    im_file = os.path.join('C:\\\\Users\\\\qa284\\\\Desktop\\\\major project final code settings\\\\@NEW BEGININIGS\\\\testing\\\\extracted_frames', 'frame_'+str(f)+'.png')\n",
    "    img = cv2.imread(im_file)\n",
    "    \n",
    "    #timer starts \n",
    "    start = time()\n",
    "    \n",
    "    img = simple_downsmpl(img,srf) \n",
    "    J = dehaze(img, r, n,window)\n",
    "    \n",
    "    #timer ends \n",
    "    end = time()\n",
    "    \n",
    "    elpsd_time =end - start\n",
    "    x_fc.append(f)\n",
    "    y_time.append(elpsd_time)\n",
    "    \n",
    "    im_file = os.path.join('C:\\\\Users\\\\qa284\\\\Desktop\\\\major project final code settings\\\\@NEW BEGININIGS\\\\testing\\\\dehazed_frames', 'frame_'+str(f)+'.png')\n",
    "    cv2.imwrite(im_file,J*255)\n",
    "    print('Dehazed frame:',f ,\"\\t | \\t Time_taken:\",y_time[f-1],\"seconds\")\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107de27",
   "metadata": {},
   "source": [
    "# Frame assembling to make dehazed video --not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = vid_obj.get(cv2.CAP_PROP_FPS)\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ea3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "fps = vid_obj.get(cv2.CAP_PROP_FPS)\n",
    "demo = cv2.imread('C:\\\\Users\\\\qa284\\\\Desktop\\\\major project final code settings\\\\@NEW BEGININIGS\\\\testing\\\\extracted_frames\\\\frame_1.png')\n",
    "demo = np.min(demo, axis = 2)\n",
    "size = demo.shape\n",
    "size = (size[1],size[0])\n",
    "print('Assembling dehazed frames to make up Video ==>')\n",
    "cap = cv2.VideoWriter(\"C:\\\\Users\\\\qa284\\\\Desktop\\\\major project final code settings\\\\@NEW BEGININIGS\\\\testing\\\\dehazed_video.avi\",cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, size)\n",
    "for i in range(1,no_of_frame+1):\n",
    "    im_file = os.path.join('C:\\\\Users\\\\qa284\\\\Desktop\\\\major project final code settings\\\\@NEW BEGININIGS\\\\testing\\\\dehazed_frames', 'frame_'+str(i)+'.png')\n",
    "    img = cv2.imread(im_file)\n",
    "    cap.write(img)\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44011a2c",
   "metadata": {},
   "source": [
    "# Timing plots and other details --not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------------------------------------------------------------------------\")\n",
    "frames = vid_obj.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = vid_obj.get(cv2.CAP_PROP_FPS)\n",
    "seconds = round(frames / fps)\n",
    "video_time = datetime.timedelta(seconds=seconds)\n",
    "print(f\"Frames per second of video--> {fps}\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(f\"video duration [hh:mm:ss]--> {video_time}\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"Total number of frames in video:\",len(res))\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"Total time for dehazing video:\",sum(res))\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"Average time for dehazing per frame:\",sum(res)/len(res))\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"maximum processing time for a frame\", max(res) )\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"minimum processing time for a frame\", min(res) )\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "# print(y_time)\n",
    "# print(\"----------------------------------------------------------------------------------\")\n",
    "# print(res)\n",
    "# print(\"----------------------------------------------------------------------------------\")\n",
    "# print(x_fc)\n",
    "# print(\"----------------------------------------------------------------------------------\")\n",
    "# print(len(y_time))\n",
    "# print(\"----------------------------------------------------------------------------------\")\n",
    "plt.scatter(x_fc,y_time)\n",
    "plt.ylabel(\"time [seconds] -->\")\n",
    "plt.xlabel(\"Frame Number-->\")\n",
    "plt.text(3, 4.95 , f'frames in video: { len(res) } ' , bbox=dict(facecolor='red', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df96976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a900ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a7f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
